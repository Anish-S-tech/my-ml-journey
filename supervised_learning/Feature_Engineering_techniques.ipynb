{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Anish-S-tech/my-ml-journey/blob/main/Feature_Engineering_techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "s6OZPGpFRK84",
    "outputId": "b324507e-322a-43cc-a59d-eb9afa41dd73"
   },
   "outputs": [],
   "source": [
    "# One hot encoding : One-Hot Encoding converts categorical variables into binary indicators, allowing them to be used by machine learning models.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {'color' : ['Red','Blue','Green','Blue']}\n",
    "df = pd.DataFrame(data)\n",
    "display(df)\n",
    "\n",
    "df_encoded = pd.get_dummies(df,columns=['color'],prefix='color')\n",
    "\n",
    "display(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "hFRhXXuwWM4V",
    "outputId": "7bfef892-94ad-4232-9b7d-7eee19d1e11a"
   },
   "outputs": [],
   "source": [
    "# Binning: Binning transforms continuous variables to discrete bins, making them categorical for easier analysis\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Age':[23, 45, 18, 34, 67, 50, 21]}\n",
    "df = pd.DataFrame(data)\n",
    "display(df)\n",
    "\n",
    "bins = [0,20,40,60,80,100]\n",
    "labels = ['0-20','20-40','40-60','60-80','80-100']\n",
    "\n",
    "df['Age_group'] = pd.cut(df['Age'],bins=bins,labels=labels,right=False)  # adds another column \"Age_group\" and categorizes the age\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DFyORsYUfVtI",
    "outputId": "acce7d12-9082-40c8-8fcd-dc7e60940bc5"
   },
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03pIadeSWc-U",
    "outputId": "6157369a-28d2-49bc-a3bb-cb0ee1b1f196"
   },
   "outputs": [],
   "source": [
    "# Text Data Preprocessing: Involves removing stop-words, stemming and vectorizing text data to prepare it for machine learning models.(using nltk)\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('stopwords')  # Downloads the \"stopwords\" resource\n",
    "texts = [\"This is a sample sentence.\", \"Text data processing is important for modeling\"]\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "  words = text.split()\n",
    "  words = [stemmer.stem(word) for word in words if word.lower() not in stop_words]\n",
    "  return \" \".join(words)\n",
    "\n",
    "cleaned_texts = [preprocess_text(text) for text in texts]\n",
    "\n",
    "X = vectorizer.fit_transform(cleaned_texts)\n",
    "\n",
    "print(\"Cleaned texts: \", cleaned_texts)\n",
    "print(\"Vectorized text: \",X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "jcD7vY1LfRXZ",
    "outputId": "3cc29310-6e67-4632-e25c-51c8b483dfd7"
   },
   "outputs": [],
   "source": [
    "# Feature splitting: Divides a single feature into multiple sub-features, uncovering valuable insights and improving model performance\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Full_Address' : [\n",
    "    '123 Elm St, SpringField, 12345', '456 Oak rd, Shelbyville, 67890'\n",
    "]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df[['Street','City','Zipcode']] = df['Full_Address'].str.extract(\n",
    "    r'([0-9]+\\s[\\w\\s]+),\\s([\\w\\s]+),\\s(\\d+)'\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "9qBQ05RVh7jV",
    "outputId": "c39e0de9-c75a-4699-8e4c-c04b07b07a0c"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Tools for feature Engineering:\n",
    "\n",
    "1. FeatureTools\n",
    "2. TPOT\n",
    "3. DataRobot\n",
    "4. Alteryx\n",
    "5. H2O.ai\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFCqq1GKixxL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOkoynZcY+qQ8O3c35ZpUGY",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
